{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Apr 17 12:43:11 2023\n",
    "\n",
    "@author: jsavage\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sympy as sym\n",
    "import numpy as np\n",
    "import math as math\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import xlsxwriter\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from openpyxl import Workbook\n",
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference, Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "w\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_import = r\"F:\\DerekS\\My Projects\\Python\\Meeder1\\Residual Xs.xlsx\"\n",
    "y_import = r\"F:\\DerekS\\My Projects\\Python\\Meeder1\\10 Year Price Return Ys.xlsx\"\n",
    "\n",
    "#For Winsorization\n",
    "upper_limit = 1\n",
    "lower_limit = 0\n",
    "\n",
    "deciles = 5\n",
    "\n",
    "lag = 0\n",
    "\n",
    "#To specify the time frame of forward returns you want to analyze. 'd' is daily, 'w' is weekly, and 'm' is monthly. Letters are lowercase.\n",
    "forward_returns = 'w'\n",
    "\n",
    "#To smooth out the x factor\n",
    "x_roll = 1\n",
    "\n",
    "print(x_roll)\n",
    "print(forward_returns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################# Dont Change Anything Under Here Unless You Know Python ############################################\n",
    "workbook = Workbook()\n",
    "wb = openpyxl.load_workbook(r'F:\\DerekS\\My Projects\\Python\\Meeder1\\Quantile Output.xlsx')\n",
    "sheet_names = wb.sheetnames\n",
    "\n",
    "for name in sheet_names:\n",
    "    sheet = wb[name]\n",
    "    wb.remove(sheet)\n",
    "new_sheet = wb.create_sheet('Sheet1')\n",
    "wb.active = new_sheet\n",
    "\n",
    "wb.save(r'F:\\DerekS\\My Projects\\Python\\Meeder1\\Quantile Output.xlsx')\n",
    "\n",
    "\n",
    "try:    \n",
    "    df_x = pd.read_excel(x_import)\n",
    "    df_x['Date'] = pd.to_datetime(df_x['Date'])\n",
    "    df_x.set_index('Date', inplace = True)\n",
    "    df_x = df_x.sort_index()\n",
    "    df_x = df_x.iloc[:,:].shift(lag)\n",
    "    \n",
    "    df_y = pd.read_excel(y_import)\n",
    "    df_y['Date'] = pd.to_datetime(df_y['Date'])\n",
    "    df_y.set_index('Date', inplace = True)\n",
    "    df_y = df_y.sort_index()\n",
    "except ValueError: \n",
    "    df_x = pd.read_csv(x_import, sep = '\\t')\n",
    "    df_x['Date'] = pd.to_datetime(df_x['Date'])\n",
    "    df_x.set_index('Date', inplace = True)\n",
    "    df_x = df_x.sort_index()\n",
    "    df_x = df_x.iloc[:,:].shift(lag)\n",
    "    \n",
    "    df_y = pd.read_csv(y_import, sep = '\\t')\n",
    "    df_y['Date'] = pd.to_datetime(df_y['Date'])\n",
    "    df_y.set_index('Date', inplace = True)\n",
    "    df_y = df_y.sort_index()\n",
    "else:\n",
    "    df_x = pd.read_excel(x_import)\n",
    "    df_x['Date'] = pd.to_datetime(df_x['Date'])\n",
    "    df_x.set_index('Date', inplace = True)\n",
    "    df_x = df_x.sort_index()\n",
    "    df_x = df_x.iloc[:,:].shift(lag)\n",
    "    \n",
    "    df_y = pd.read_excel(y_import)\n",
    "    df_y['Date'] = pd.to_datetime(df_y['Date'])\n",
    "    df_y.set_index('Date', inplace = True) \n",
    "    df_y = df_y.sort_index()    \n",
    "        \n",
    "df_x_raw = df_x    \n",
    "\n",
    "    \n",
    "df_xy = pd.merge(df_y, df_x_raw, on='Date')\n",
    "df_xy = df_xy.sort_index()\n",
    "\n",
    "df_decile = pd.DataFrame()\n",
    "summary_df = pd.DataFrame()\n",
    "\n",
    "x_factors = df_xy.iloc[:,1:]\n",
    "y = df_xy.iloc[:,0]\n",
    "y_factor = y.name\n",
    "first_date = df_xy.index.min()\n",
    "first_date = first_date.strftime('%Y-%m-%d')\n",
    "last_date = df_xy.index.max()\n",
    "last_date = last_date.strftime('%Y-%m-%d')\n",
    "\n",
    "reg_dict = {}\n",
    "rsquared_dict = {}\n",
    "plots = []\n",
    "results_df = pd.DataFrame()\n",
    "decile_dict = {}\n",
    "pvalue_dict = {}\n",
    "df_fake = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dstockman\\AppData\\Local\\Temp\\ipykernel_12164\\2457650557.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  pvalue_dict[factor] = reg.pvalues[1]\n",
      "C:\\Users\\dstockman\\AppData\\Local\\Temp\\ipykernel_12164\\2457650557.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  results_dict = {'R-squared': reg.rsquared, 'p-value': reg.pvalues[1]}\n",
      "C:\\Users\\dstockman\\AppData\\Local\\Temp\\ipykernel_12164\\2457650557.py:127: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  pvalue_dict[factor] = reg.pvalues[1]\n",
      "C:\\Users\\dstockman\\AppData\\Local\\Temp\\ipykernel_12164\\2457650557.py:136: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  results_dict = {'R-squared': reg.rsquared, 'p-value': reg.pvalues[1]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for factor in df_xy:\n",
    "    try:\n",
    "        df_reg = df_xy[[y_factor, factor]]\n",
    "        df_fake[factor + 'Decile'] = pd.qcut(df_reg[factor], deciles, labels=False)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    else:\n",
    "            if factor == y_factor:\n",
    "                continue\n",
    "            df_reg = pd.DataFrame()\n",
    "            df_reg = df_xy[[y_factor, factor]]\n",
    "            df_reg = df_reg.dropna()\n",
    "            if forward_returns == 'd':\n",
    "                pass\n",
    "            elif forward_returns == 'w':\n",
    "                df_reg[factor] = df_reg[factor].rolling(window=x_roll).mean()\n",
    "                df_reg[y_factor] = df_y.rolling(window=5).sum().shift(-5)\n",
    "                df_reg = df_reg.resample('W').last()\n",
    "            elif forward_returns == 'm':\n",
    "                df_reg[factor] = df_reg[factor].rolling(window=x_roll).mean()\n",
    "                df_reg[y_factor] = df_y.rolling(window=21).sum().shift(-21)\n",
    "                df_reg = df_reg.resample('M').last()\n",
    "            else:\n",
    "                print('Please provide a valid forward_return time frame')\n",
    "                sys.exit()\n",
    "            reg_upperlimit = df_reg[factor].quantile(upper_limit)\n",
    "            reg_lowerlimit = df_reg[factor].quantile(lower_limit)\n",
    "            df_reg['winsorized ' + factor] = df_reg[factor].clip(reg_lowerlimit, reg_upperlimit)\n",
    "            df_reg = df_reg.dropna()\n",
    "            y = df_reg.iloc[:,0]\n",
    "            x = df_reg[factor]\n",
    "            x = sm.add_constant(x)\n",
    "            reg = sm.OLS(y,x).fit()\n",
    "            reg_dict[factor] = reg\n",
    "            rsquared_dict[factor] = reg.rsquared\n",
    "            pvalue_dict[factor] = reg.pvalues[1]\n",
    "            df_decile = pd.DataFrame()\n",
    "            df_decile[factor + 'Decile'] = pd.qcut(df_reg[factor], deciles, labels=False)\n",
    "            df_decile['Returns'] = y\n",
    "            avg_returns = df_decile.groupby(factor + 'Decile')[\"Returns\"].mean()\n",
    "            decile_dict[factor] = avg_returns\n",
    "            n = df_decile.shape[0] / deciles\n",
    "            tstat_calc = (df_decile.groupby(factor + 'Decile')[\"Returns\"].mean() / df_decile.groupby(factor + 'Decile')[\"Returns\"].std()) * math.sqrt(n)\n",
    "\n",
    "        \n",
    "         # write the deciles to a new sheet in the Excel file\n",
    "            results_dict = {'R-squared': reg.rsquared, 'p-value': reg.pvalues[1]}\n",
    "            factor_sheet_name = factor[:29].replace('/','')\n",
    "            new_sheet_name = wb.create_sheet(factor_sheet_name)\n",
    "            new_sheet_name.cell(row=1, column=1, value = factor)\n",
    "            new_sheet_name.cell(row=3, column=1, value = 'Deciles')\n",
    "            for d in range(1,1+deciles):\n",
    "                new_sheet_name.cell(row=d+3, column=1, value=d)\n",
    "            for index, value in avg_returns.items():\n",
    "                index = int(index)\n",
    "                new_sheet_name.cell(row=index+4, column=2, value=round(value,4))\n",
    "            i = 0\n",
    "            for tstat in tstat_calc:\n",
    "                new_sheet_name.cell(row=i+4, column=3, value=round(tstat,4))\n",
    "                i = i+1\n",
    "            sheet = wb[factor_sheet_name]\n",
    "            data = Reference(sheet, min_col=2, min_row=4, max_col=2, max_row= 3 + deciles)\n",
    "            chart = BarChart()\n",
    "            chart.add_data(data)\n",
    "            chart.title = factor + \" Decile Analysis\"\n",
    "            chart.x_axis.title = 'Deciles'\n",
    "            chart.y_axis.title = 'Returns'\n",
    "            sheet.add_chart(chart, 'E7')\n",
    "            new_sheet_name.cell(row=1, column=4, value = 'R-squared')\n",
    "            new_sheet_name.cell(row=2, column=4,value = round(results_dict['R-squared'],4))\n",
    "            new_sheet_name.cell(row=1, column=5,value = 'p-value')\n",
    "            new_sheet_name.cell(row=2, column=5,value = round(results_dict['p-value'],4))\n",
    "\n",
    "x_factors_differenced = pd.DataFrame()\n",
    "positive_check = (x_factors.dropna() >= 0).all()\n",
    "for col in x_factors:\n",
    "    if positive_check[col]:\n",
    "        x_factors_differenced[col] = df_x[col].pct_change()\n",
    "    if not positive_check[col]:\n",
    "        x_factors_differenced[col] = df_x[col].diff()\n",
    "        \n",
    "\n",
    "        \n",
    "word = 'Differenced '\n",
    "x_factors_differenced.columns = [word + col for col in x_factors_differenced.columns]\n",
    "y = df_xy.iloc[:,0]\n",
    "\n",
    "df_xy_diff = pd.merge(y, x_factors_differenced, on='Date')\n",
    "y = df_xy_diff.iloc[:,0]\n",
    "#x_factors_differenced = df_xy_diff.iloc[:,1:]\n",
    "df_decile_diff = pd.DataFrame()\n",
    "\n",
    "for factor in df_xy_diff:\n",
    "    try:\n",
    "        df_fake[factor + 'Decile'] = pd.qcut(df_xy_diff[factor], deciles, labels=False)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    else:\n",
    "       if factor == y_factor:\n",
    "            continue\n",
    "       df_reg = df_xy_diff[[y_factor, factor]]\n",
    "       df_reg = df_reg.dropna()\n",
    "       if forward_returns == 'd':\n",
    "           pass\n",
    "       elif forward_returns == 'w':\n",
    "           df_reg = df_reg.rolling(window=x_roll).mean()\n",
    "           df_reg[y_factor] = df_y.rolling(window=5).sum().shift(-5)\n",
    "           df_reg = df_reg.resample('W').last()\n",
    "       elif forward_returns == 'm':\n",
    "           df_reg = df_reg.rolling(window=x_roll).mean()\n",
    "           df_reg[y_factor] = df_y.rolling(window=21).sum().shift(-21)\n",
    "           df_reg = df_reg.resample('M').last()\n",
    "       reg_upperlimit = df_reg[factor].quantile(upper_limit)\n",
    "       reg_lowerlimit = df_reg[factor].quantile(lower_limit)\n",
    "       df_reg['winsorized ' + factor] = df_reg[factor].clip(reg_lowerlimit, reg_upperlimit)\n",
    "       y = df_reg.iloc[:,0]\n",
    "       y = y.dropna()\n",
    "       x = df_reg[factor]\n",
    "       x = x.dropna()\n",
    "       x = sm.add_constant(x)\n",
    "       align = pd.merge(x,y, on='Date')\n",
    "       x = align.iloc[:,:2]\n",
    "       y = align.iloc[:,2]\n",
    "       reg = sm.OLS(y,x).fit()\n",
    "       reg_dict[factor] = reg\n",
    "       rsquared_dict[factor] = reg.rsquared\n",
    "       pvalue_dict[factor] = reg.pvalues[1]\n",
    "       df_decile_diff = pd.DataFrame()\n",
    "       df_decile_diff[factor + 'Decile'] = pd.qcut(df_reg[factor], deciles, labels=False)\n",
    "       df_decile_diff['Returns'] = y\n",
    "       avg_returns_differenced = df_decile_diff.groupby(factor + 'Decile')[\"Returns\"].mean()\n",
    "       decile_dict[factor] = avg_returns_differenced\n",
    "       n = df_decile_diff.shape[0] / deciles\n",
    "       tstat_diff = (df_decile_diff.groupby(factor + 'Decile')[\"Returns\"].mean() / df_decile_diff.groupby(factor + 'Decile')[\"Returns\"].std()) * math.sqrt(n)\n",
    "       \n",
    "       results_dict = {'R-squared': reg.rsquared, 'p-value': reg.pvalues[1]}\n",
    "       factor_sheet_name = factor[:29].replace('/','')\n",
    "       new_sheet_name = wb.create_sheet(factor_sheet_name)\n",
    "       new_sheet_name.cell(row=1, column=1, value = factor)\n",
    "       new_sheet_name.cell(row=3, column=1, value = 'Deciles')\n",
    "       for d in range(1,1+deciles):\n",
    "           new_sheet_name.cell(row=d+3, column=1, value=d)\n",
    "       for index, value in avg_returns_differenced.items():\n",
    "           index = int(index)\n",
    "           new_sheet_name.cell(row=index+4, column=2, value=round(value,4))\n",
    "       i = 0\n",
    "       for tstat in tstat_diff:\n",
    "           new_sheet_name.cell(row=i+4, column=3, value=round(tstat,4))\n",
    "           i = i+1\n",
    "       sheet = wb[factor_sheet_name]\n",
    "       data = Reference(sheet, min_col=2, min_row=4, max_col=2, max_row= 3 + deciles)\n",
    "       chart = BarChart()\n",
    "       chart.add_data(data)\n",
    "       chart.title = factor + \" Decile Analysis\"\n",
    "       chart.x_axis.title = 'Deciles'\n",
    "       chart.y_axis.title = 'Returns'\n",
    "       sheet.add_chart(chart, 'E7')\n",
    "       new_sheet_name.cell(row=1, column=4, value = 'R-squared')\n",
    "       new_sheet_name.cell(row=2, column=4,value = round(results_dict['R-squared'],4))\n",
    "       new_sheet_name.cell(row=1, column=5,value = 'p-value')\n",
    "       new_sheet_name.cell(row=2, column=5,value = round(results_dict['p-value'],4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:42: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:42: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\dstockman\\AppData\\Local\\Temp\\ipykernel_12164\\1274125686.py:42: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  writer = pd.ExcelWriter(\"F:\\DerekS\\My Projects\\Python\\Meeder1\\Correlation Matrix.xlsx\" ,engine= 'xlsxwriter')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sheet = wb[\"Sheet1\"]\n",
    "sheet.cell(row = 1, column=5, value = 'R-Squared and Decile Summary for Factors against ' + y_factor)\n",
    "date_range = str(first_date) + ' to ' + str(last_date)\n",
    "sheet.cell(row = 2, column = 5, value = date_range)\n",
    "counter = 1\n",
    "sheet.cell(row=1,column=1,value='Factors')\n",
    "sheet.cell(row=1,column=2,value='R-squared')\n",
    "sheet.cell(row=1,column=3,value='P-Values')\n",
    "for key, value in rsquared_dict.items():\n",
    "     counter = counter+1\n",
    "     sheet.cell(row=counter+1, column=1, value=key)\n",
    "counter=1\n",
    "for key, value in rsquared_dict.items():\n",
    "    counter = counter+1\n",
    "    sheet.cell(row=counter+1, column=2, value=round(value,4))\n",
    "counter=1\n",
    "for key, value in pvalue_dict.items():\n",
    "    counter = counter+1\n",
    "    sheet.cell(row=counter+1, column=3, value=round(value,2))   \n",
    "counter=1\n",
    "for d in range(1,deciles+1):\n",
    "    sheet.cell(row=4+d, column=5, value = d)\n",
    "for key, value in decile_dict.items():\n",
    "    counter = counter + 1\n",
    "    sheet.cell(row=4, column=4+counter, value = key)\n",
    "counter = 1\n",
    "for key, value in decile_dict.items():\n",
    "    dict_counter = 0 \n",
    "    counter = counter + 1\n",
    "    for c in range(1,deciles+1):\n",
    "        sheet.cell(row=4+c, column=4+counter, value = value[dict_counter])\n",
    "        dict_counter = dict_counter + 1\n",
    "        if dict_counter == deciles:\n",
    "            break   \n",
    "        \n",
    "df_correlation = pd.merge(x_factors, x_factors_differenced, on='Date')\n",
    "correlation_matrix = df_correlation.corr()\n",
    "\n",
    "wb.save(r'F:\\DerekS\\My Projects\\Python\\Meeder1\\Quantile Output.xlsx')\n",
    "wb.close()\n",
    "\n",
    "writer = pd.ExcelWriter(\"F:\\DerekS\\My Projects\\Python\\Meeder1\\Correlation Matrix.xlsx\" ,engine= 'xlsxwriter')\n",
    "workbook = writer.book\n",
    "\n",
    "worksheet = workbook.add_worksheet(\"Matrix\")\n",
    "writer.sheets[\"Matrix\"] = worksheet\n",
    "correlation_matrix.to_excel(writer,sheet_name=\"Matrix\",startrow=0,startcol=0)\n",
    "# Save and close the writer\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
